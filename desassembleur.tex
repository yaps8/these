

% \section{Analyse dynamique et auto-modification}
% L'analyse dynamique consiste donc à se baser sur une ou des exécutions particulières d'un programme pour inférer des propriétés sur son fonctionnement.
% Elle demande donc de se munir d'une langage modélisant le fonctionnement de la machine durant l'exécution du programme, d'une sémantique concrète de l'assembleur utilisé et de lancer l'évaluation sémantique du programme sur une ou plusieurs entrées.
% Les entrées d'un programme sont par exemple les paramètres passés lors de l'appel au programme, l'état de la machine lors du démarrage, les données lues depuis la mémoire et les saisies faites par l'utilisateur au clavier ou à la souris lors de l'exécution s'il s'agit d'une application dotée d'une interface graphique.
% Dans cette partie nous reprendrons la sémantique simplifiée pour un langage assembleur définie au chapitre précédent et expliquerons comment séparer une exécution d'un programme auto-modifiant en plusieurs sous-exécution non auto-modifiantes afin d'utiliser des techniques standard d'analyse sur chacune de ces sous-exécutions.

Nous avons précédemment détaillé plusieurs techniques d'obscurcissement de code. 
Nous avons décrit des méthodes d'analyse de programmes \nsm\ présentant des chevauchements de code et une méthode permettant de ramener l'analyse d'un programme \sm\ à l'analyse de plusieurs programmes \nsms\ par découpage en instantanés.

Dans ce chapitre nous présentons une méthode d'analyse combinant l'approche dynamique pour gérer les programmes \sms\ et une analyse statique de chaque sous programme considéré à partir d'un instantané et de la trace d'exécution.

\section{Désassemblage parfait}
% \subsection{}
Nous avons, au chapitre \ref{chap:assembleur}, défini le désassemblage parfait d'un programme \nsm\ comme la donnée de l'ensemble des adresses auxquelles des instructions peuvent être atteintes lors de l'exécution.
Dans le cas d'un programme \sm, cette définition n'est pas suffisante puisque l'instruction présente à une adresse dépend du contexte d'exécution et des éventuelles modifications qui ont été faites à cette adresse.

Nous considérons toujours que la donnée que l'analyste cherche à déterminer et représenter est l'ensemble des exécution possibles du programme : nous notons $E_T$ l'ensemble des traces d'exécution.
En particulier une entrée spécifique provoque une exécution que nous observons sous la forme d'une trace.
Cette trace peut être découpée en niveaux d'exécution et en autant d'instantanés de la mémoire (définition \ref{def:instantane}), enfin chaque vague est le désassemblage parfait de l'instantané.

Le désassemblage, pris au sens de l'opération inverse de l'assemblage,
consiste à déterminer les adresses contenant des instructions, les
autres contenant des données.
Au sein d'une exécution les octets sur lesquelles une instruction ayant
un niveau d'exécution strictement supérieur à 1, c'est à dire que ces
octets ont été modifiés avant que l'instruction ne soit exécutée, ne
sont présents dans la représentation d'origine du programme qu'en temps
que données.
Ainsi le désassemblage, en tant qu'opération inverse de l'assembleur, d'un programme \sm\ ne prend en compte
que les instructions exécutées avec un le niveau d'exécution 1
(définition \ref{def:desassemblage_parfait_sm}).

\begin{defi}
 Étant donné un programme P \sm\ et l'ensemble de ses traces d'exécution
$E_T$, l'opération inverse de l'assemblage de P est la donnée de l'ensemble des adresses où une
instruction de niveau d'exécution 1 est exécutée dans au moins une
trace, c'est à dire~$\{a, \exists\ T\in E_T, \exists\ (i, X, D)\in T, X=1,\ $\da{D}$=a\}$.
\label{def:desassemblage_parfait_sm}
\end{defi}

Nous étendons cependant la notion de désassemblage parfait aux programmes \sms\ pour qu'elle inclue toutes les instructions exécutées (définition \ref{def:desassemblage_parfait_sm2}).

\begin{defi}
 Étant donné un programme P \sm\ et l'ensemble de ses traces d'exécution
$E_T$, le désassemblage parfait de P est la donnée de l'ensemble des adresses exécutées dans une exécution du programme et de l'instruction alors exécutée, c'est à dire~$\{(\mda{D}, \mdi{D}), (i, X, D)\in T, T\in E_T\}$.
\label{def:desassemblage_parfait_sm2}
\end{defi}

\subsection{Graphe de flot de contrôle simple}
Le graphe de flot de contrôle ne peut plus se contenter de représenter
une instruction par son adresse puisque plusieurs instructions
différentes peuvent être présentes à la même adresse.
Le graphe de flot de contrôle simple, extension du GFC parfait défini pour les programmes \nsms, est le graphe dont les sommets sont des couples $(a, I)$ provenant du désassemblage parfait du programme. Il y a un arc entre deux sommets si le second suit directement le premier dans une trace d'exécution (définition \ref{def:cfg_naif_sm}).

\begin{defi}
 Étant donné un programme \sm\ P et l'ensemble de ses traces d'exécution
$E_T$, le graphe de flot de contrôle simple de P est le graphe orienté
$G=(V, E)$ tel que :
 \begin{itemize}
  \item $V=\{(\mda{D}, \mdi{D}), (i, X, D)\in T, T\in E_T\}$
  \item $((a_1, I_1), (a_2, I_2))\in E\ si\ et\ seulement\ si\ (a_1,
I_1)\ et\ (a_2, I_2)\ se\ suivent\ dans\ une\ trace\ : \exists T\in
E_T,\ i\in \BN, (i, X_1, D_1)\ et\ (i+1, X_2, D_2)\in T\ avec\
$\da{D_1}$=a_1,\ $\di{D_1}$=I_1,$~\da{D_2}$=a_2,\ $\di{D_2}$=I_2$.
 \end{itemize}
\label{def:cfg_naif_sm}
\end{defi}

Le problème de cette définition d'un GFC pour un programme \sm\ est qu'%e souvent les vagues se suivent et ont peu de rapport les unes avec les autres.
elle ne permet pas de visualiser l'enchaînement des niveaux d'exécution et peut conduire à une interprêtation biaisée des exécutions possibles.

\paragraph{Exemple.}
Prenons le programme donné en figure \ref{fig:sm_asm} dont le graphe de flot de contrôle construit par analyse statique à l'aide d'un parcours récursif est en figure \ref{fig:sm_cfg_statique}.

\begin{figure}[h]
\begin{center}
% \subfigure[]{
\begin{tabular}[b]{|l|l|l|l|}
\hline
Adresse & Octets & Instruction & Instruction écrite\\ 
\hline
 8048060 <debut>  &  31 ff             &  xor    edi,edi		& \\
 8048062  &  40                        &  inc    eax			& \\
 8048063  &  74 07                     &  je     804806c <si\_zero> 	& \\
 	  &			       &				& \\
 8048065  &  bf 02 00 00 00            &  mov    edi, 0x2 		& \\
 804806a  &  eb f4                     &  jmp    8048060 <debut> 	& \\
	  &			       &				& \\
 804806c <si\_zero> &  bf 01 00 00 00  &  mov    edi, 0x1 		& \\
 8048071  &  bb 60 80 04 08            &  mov    ebx, 0x8048060 	& \\
 8048076  &  66 c7 03 47 00            &  mov    [ebx], 0x47 		& inc edi\\
 804807b  &  66 c7 43 01 47 00         &  mov    [ebx+0x1], 0x47	& inc edi \\
 8048081  &  66 c7 43 03 c3 00         &  mov    [ebx+0x3], 0xc3	& ret \\
 8048087  &  eb d7                     &  jmp    8048060 <debut> 	& \\
\hline
\end{tabular}
\caption{Code \sm}
\label{fig:sm_asm}
\end{center}
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.8\textwidth]{supports/disas_sm/ex2_statique.pdf}
% \label{fig:sm_cfg_statique}
% }
\caption{GFC par analyse statique et récursive}
\label{fig:sm_cfg_statique}
\end{center}
\end{figure}

% \FloatBarrier

La branche du saut effectué à l'adresse \adr{0x8048063} dans le cas où \eax\ est différent de zéro revient vers le point d'entrée, incrémente \eax\ et passe à nouveau dans le saut conditionnel. Cette boucle provoquera à terme un dépassement d'entier sur la valeur \eax\ qui sera remise à zéro et l'autre branche du saut sera appelée.
Cette seconde branche a pour effet de modifier les instructions aux adresses \adr{0x8048060}, \adr{0x8048061} et \adr{0x8048063} pour y placer les instructions \texttt{inc edi}, \texttt{inc edi} et \texttt{ret} respectivement, puis de sauter sur l'adresse \adr{0x8048060}, provoquant l'exécution des instructions écrites ainsi que de l'instruction \texttt{inc eax}, non modifiée.

Ainsi toutes les exécutions possibles, paramétrées par la valeur initiale d'\eax, bouclent sur la branche conditionnelle un nombre fini, qui peut être nul, de fois et exécutent la seconde branche, qui met la valeur 1 dans \edi, provoque une auto-modification, incrémente \edi\ deux fois puis quitte la fonction. Dans toutes les exécutions possibles la valeur finale de \edi\ est toujours 3.

Le GFC simple de ce programme est donné en figure \ref{fig:sm_cfg_parfait}. En raison du mélange des instructions à différents niveaux d'exécution, il n'est pas possible de distinguer les vagues d'exécution et un analyseur statique simple approxime la valeur de \edi\ à 2 ou 3.

\begin{figure}[h]
\begin{center}
  \includegraphics[width=0.7\textwidth]{supports/disas_sm/ex2_parfait.pdf}
\end{center}
\caption{GFC simple}
\label{fig:sm_cfg_parfait}
\end{figure}



Cette difficulté n'est pas intrinsèque aux programmes \sm\ et provient du fait même que le graphe de flot de contrôle est sur une \sura\ de l'ensemble des exécutions possibles. Il est cependant exacerbé dans le cas des programmes \sm\ puisque souvent les vagues successives n'ont que peu de code commun entre elles et il n'est pas cohérent de les mélanger dans le CFG.

\FloatBarrier
\subsection{Graphe de flot de contrôle parfait\label{sec:gfc_parfait}}

Chaque trace est constituée d'une suite d'instructions et d'un enchaînement d'instantanés de la mémoire, chacun représentant un niveau d'exécution.
Il est possible que les instantanés d'une même trace soient deux à deux distincts comme il est possible que des instantanés soient identiques à des niveaux d'exécution différents, en raison de la définition strictement croissante des niveaux d'exécution.
De même plusieurs traces différentes peuvent converger vers les mêmes instantanés.

Prenons les quatre enchaînements de niveaux d'exécution et leurs instantanés respectifs suivants :
$T_1 = s_1, s_2, s_1, s_5, s_6$ ; 
$T_2 = s_1, s_2, s_3, s_5, s_6$ ; 
$T_3 = s_1, s_2, s_3, s_4$ ; 
$T_4 = s_1, s_2, s_4$.

On peut représenter (figure \ref{fig:arbre_vagues}) ces enchaînements sous la forme d'un graphe acyclique ayant une racine qui est l'instantané au premier niveau d'exécution : il s'agit toujours de la représentation initiale du binaire.

\begin{figure}[h]
\begin{center}
\begin{tikzpicture}[
%   tlabel/.style={pos=0.4,right=-1pt},
%   every node/.style={color=black, circle, minimum size=10mm, draw=black, align=center},
%   edge from parent/.style={->, draw=black},
%   level 1/.style={sibling distance=30mm, level distance=15mm},
  thick
]
\node (ROOT) {$s_1$}
% \node (S11){Site 1};
child {node (S2) {$s_2$}
child{node (S3) {$s_1$}
child {node (S4) {$s_5$}
  child {node (S6) {$s_6$}}
}
}
child{node (S7) {$s_3$}
child {node (S8) {$s_4$}
}
}
child {node (S9) {$s_4$}}
};
% \draw (S4) -> (S5);
\path (ROOT) edge [->] (S2);
\path (S2) edge [->] (S3);
\path (S2) edge [->] (S7);
\path (S2) edge [->] (S9);
\path (S3) edge [->] (S4);
\path (S4) edge [->] (S6);
\path (S7) edge [->] (S8);
\path (S7) edge [->] (S4);
\node[draw=none, left=2.5cm of ROOT.west, anchor=east, text width=5cm, minimum size=5cm] (V1){Niveau d'exécution (X) 1};
\node[draw=none, below=15mm of V1.north, text width=5cm, minimum size=5cm] (V2){Niveau d'exécution (X) 2};
\node[draw=none, below=15mm of V2.north, text width=5cm, minimum size=5cm] (V3){Niveau d'exécution (X) 3};
\node[draw=none, below=15mm of V3.north, text width=5cm, minimum size=5cm] (V4){Niveau d'exécution (X) 4};
\node[draw=none, below=15mm of V4.north, text width=5cm, minimum size=5cm] (V5){Niveau d'exécution (X) 5};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
\end{tikzpicture}
\end{center}
\caption{Différents instantanés des traces d'exécution et leur niveau d'exécution}
\label{fig:arbre_vagues}
\end{figure}

Nous considérons que mélanger dans le GFC les instructions atteignables à des niveaux d'exécution différents ne permet pas au GFC d'être une bonne représentation des exécutions possibles puisqu'on perd la notion d'enchaînement des vagues.
Ainsi chaque sommet du graphe est caractérisé par le niveau d'exécution de l'instruction, l'instantané dans lequel elle a été analysée, l'adresse de l'instruction et enfin l'instruction.
Cette représentation permet d'isoler chaque couple (niveau d'exécution, instantané) dans une sous partie du GFC qui sera le désassemblage parfait, \nsm, de l'instantané, c'est à dire la vague.
Un exemple de cette représentation est donnée en figure \ref{fig:sm_cfg_parfait_sm} où le point d'entrée est coloré en orange : il est présent au niveau d'exécution 1 dans l'instantané $s_1$ tandis que les points de sortie sont colorés en bleu clair.

\begin{figure}[h]
\begin{center}
  \includegraphics[width=1.0\textwidth]{supports/disas_sm/plus_que_parfait_cropped0.pdf}
\end{center}
\caption{GFC parfait pour un programme \sm}
\label{fig:sm_cfg_parfait_sm}
\end{figure}

Nous donnons la définition d'une exécution (définition \ref{def:execution2}), issue du résultat de l'analyse dynamique définie au chapitre précédent. L'exécution d'un programme sur une entrée I est caractérisée, via l'algorithme \ref{algo:analyse_dyn_vagues}, par le couple $(T, S)$ où $T$ est une trace et $S$ une liste d'instantanés d'exécution, un pour chaque niveau d'exécution.

\begin{defi}
 Soit un programme P prenant une entrée et ayant pour point d'entrée $ep$.
 $(T, S)$ est une exécution de P si et seulement si il existe une entrée I telle que (T, S)=\texttt{exécution(P, I, ep)}.

 On note $E_X$ l'ensemble des exécutions de P : $E_X=\bigcup_I\{\texttt{exécution(P, I, ep)}\}$.
\label{def:execution2}
\end{defi}

% Le GFC paramétré (définition \ref{def:cfg_param_sm}) représente chaque instruction contenue dans une trace dont l'exécution est compatible avec l'exécution de référence comme un sommet en prenant en compte son niveau d'exécution, son adresse et l'instruction assembleur. Deux sommets sont reliés par un arc si, dans une trace d'une exécution compatible, leurs deux instructions se suivent immédiatement.

Formellement le GFC parfait (définition \ref{def:cfg_parfait_sm2}) est constitué de toutes les instructions présentes dans une trace, représentées par leur niveau d'exécution, leur instantané, leur adresse et l'instruction ; deux sommets sont liés si et seulement si ils se suivent dans une trace d'exécution.

\begin{defi}
 Étant donné un programme P \sm\ et $E_X$ l'ensemble des exécutions de P.
 Nous appelons GFC parfait le graphe $G=(V, E)$ tel que :
 \begin{itemize}
  \item $V=\{(X,\ S[X],\ $\da{D}$,\ $\di{D}$), (T, S)\in E_X, (i, X, D)\in T\}$%\in E_C, \exists\ (i, X, D)\in T',\
%$\da{D}$=a,\ $\di{D}$=I\}$
  \item $((X_1, s_1, a_1, I_1), (X_2, s_2, a_2, I_2))\in E$ si et seulement si $(X_1, s_1, a_1,
I_1)$ et $(X_2, s_2, a_2, I_2)$ se suivent dans une trace : $\exists (T, S)\in
E_X,\ i\in \BN, (i, X_1, D_1)\ et\ (i+1, X_2, D_2)\in T$ avec \da{D_1}$=a_1,\ $\di{D_1}$=I_1,$~\da{D_2}$=a_2,\ $\di{D_2}$=I_2$, $s_1=S[X_1]$ et $s_2=S[X_2]$.
 \end{itemize}
\label{def:cfg_parfait_sm2}
\end{defi}

Il est à noter que les instructions représentées dans le graphe de flot de contrôle parfait sont exactement les mêmes que celles présentes dans le graphe de flot simple de la définition \ref{def:cfg_naif_sm}.
La différence tient dans l'agencement des sommets dans le graphe : un sommet du GFC parfait prenant en compte le niveau d'exécution, une instruction dynamique peut être présente dans plusieurs sommets différents si elle est exécutées à différents niveaux d'exécution.

\FloatBarrier
\subsection{Revue de littérature}
Anckaert, Madou et Bosschere \cite{AMB06} proposent d'introduire la représentation sous forme d'octets de chaque instruction au sein du graphe de flot de contrôle et d'ajouter aux arcs les conditions sur les octets en mémoire. Sur l'exemple précédent, leur GFC, présenté en figure \ref{fig:sm_cfg_parfait_amb}, est identique au GFC simple mais il est alors possible de différencier les chemins selon l'état de la mémoire et donc plus précis pour une analyse automatique.
En fait le graphe qu'ils représentent est un automate, permettant de compléter la notion d'automate de flot de contrôle introduit comme extension au graphe de flot de contrôle \cite{HJMS02} pour des programmes \sms.

\begin{figure}[h]
\begin{center}
  \includegraphics[width=0.8\textwidth]{supports/disas_sm/ex2_parfait_amb.pdf}
\end{center}
\caption{GFC simple augmenté des octets et des conditions de transition}
\label{fig:sm_cfg_parfait_amb}
\end{figure}

\section{Graphe de flot de contrôle paramétré par une exécution}
Nous proposons une représentation du GFC basée sur une exécution particulière et son découpage en différents niveaux d'exécution.
Cette représentation nous donne une approximation du graphe de flot parfait présenté en section \ref{sec:gfc_parfait}.
L'exécution choisie, dite de référence, consiste en une trace et un enchaînement d'instantanés de chaque niveau d'exécution.
% Chaque instantané est pris comme un programme ayant pour point d'entrée la première instruction de la trace ayant le niveau d'exécution correspondant et un point de sortie étant la dernière instruction ayant ce même niveau d'exécution.

Nous appelons GFC paramétré par cette exécution le GFC parfait du même programme dont l'ensemble de exécutions serait réduit à cette seule exécution choisie.
% Cette définition nous permet en fait de construire le GFC des seules exécutions dont les instantanés sont identiques à ceux de l'exécution de référence, on dit alors que ces exécutions sont compatibles (définition \ref{def:executions_compatibles}).
% 
% \begin{defi}
%  Soit un programme P et $(T, S)$ et $(T', S')$ deux exécutions de P.
%  $(T, S)$ et $(T', S')$ sont dites compatibles si et seulement si $S=S'$.
% \label{def:executions_compatibles}
% \end{defi}

Le GFC paramétré (définition \ref{def:cfg_param_sm}) représente chaque instruction contenue dans la trace comme un sommet en prenant en compte son niveau d'exécution, son adresse et l'instruction assembleur. Deux sommets sont reliés par un arc si, dans la trace, leurs deux instructions se suivent immédiatement.

% \begin{defi}
%  Étant donné un programme P \sm, $(T, S)$ une exécution de P et $E_C$ l'ensemble des exécutions de P compatibles avec $(T, S)$.
%  Nous appelons GFC paramétré par $T$ le graphe $G=(V, E)$ tel que :
%  \begin{itemize}
%   \item $V=\{(X,\ $\da{D}$,\ $\di{D}$), (i, X, D)\in T',\ (T', S')\in E_C \}$%\in E_C, \exists\ (i, X, D)\in T',\
% %$\da{D}$=a,\ $\di{D}$=I\}$
%   \item $((X_1, a_1, I_1), (X_2, a_2, I_2))\in E$ si et seulement si $(X_1, a_1,
% I_1)\ et\ (X_2, a_2, I_2)$ se suivent dans une trace : $\exists (T', S')\in
% E_C,\ i\in \BN, (i, X_1, D_1)\ et\ (i+1, X_2, D_2)\in T$ avec \da{D_1}$=a_1,\ $\di{D_1}$=I_1,$~\da{D_2}$=a_2,\ $\di{D_2}$=I_2$.
%  \end{itemize}
% \label{def:cfg_param_sm}
% \end{defi}

\begin{defi}
 Étant donné un programme P \sm\ et $(T, S)$ une exécution de P.
 Nous appelons GFC paramétré par $T$ le graphe $G=(V, E)$ tel que :
 \begin{itemize}
  \item $V=\{(X,\ $\da{D}$,\ $\di{D}$), (i, X, D)\in T\}$%\in E_C, \exists\ (i, X, D)\in T',\
%$\da{D}$=a,\ $\di{D}$=I\}$
  \item $((X_1, a_1, I_1), (X_2, a_2, I_2))\in E$ si et seulement si $(X_1, a_1,
I_1)\ et\ (X_2, a_2, I_2)$ se suivent dans la trace : $(i, X_1, D_1)\ et\ (i+1, X_2, D_2)\in T$ avec \da{D_1}$=a_1,\ $\di{D_1}$=I_1,$~\da{D_2}$=a_2,\ $\di{D_2}$=I_2$.
 \end{itemize}
\label{def:cfg_param_sm}
\end{defi}


Un tel GFC pour le programme \sm\ précédent est donné en figure \ref{fig:sm_cfg_vagues} : l'exécution prise en compte est celle démarrant avec \eax=-2. La boucle directe est exécutée une fois, puis comme \eax=0, la partie auto-modifiante est activée. Dans l'exemple choisi ici, toutes les exécution partagent le même découpage en vagues et le GFC est séparé en deux GFC partiels (définition \ref{def:GFC_partiel}), celui de la vague 1 et celui de la vague 2.

\begin{defi}
 On appelle GFC partiel paramétré par une exécution $(T, S)$ et un instantané du niveau d'exécution $X$ le GFC paramétré par $T$ restreint aux sommets dont le niveau d'exécution est $X$.
\label{def:GFC_partiel}
\end{defi}


% \begin{defi}
%  Étant donné un programme \sm\ P et une trace d'exécution $T$, le graphe de flot de contrôle de P paramétré par $T$ est $G=(V, E)$ tel que :
%  \begin{itemize}
%   \item $V=\{(a, I),  \exists\ T\in E_T, \exists\ (i, X, D)\in T,\
% $\da{D}$=a,\ $\di{D}$=I\}$
%   \item $((a_1, I_1), (a_2, I_2))\in E\ si\ et\ seulement\ si\ (a_1,
% I_1)\ et\ (a_2, I_2)\ se\ suivent\ dans\ une\ trace\ : \exists T\in
% E_T,\ i\in \BN, (i, X_1, D_1)\ et\ (i+1, X_2, D_2)\in T\ avec\
% $\da{D_1}$=a_1,\ $\di{D_1}$=I_1,$~\da{D_2}$=a_2,\ $\di{D_2}$=I_2$.
%  \end{itemize}
% \label{def:cfg_param_sm}
% \end{defi}

\begin{figure}[h]
\begin{center}
  \includegraphics[width=0.6\textwidth]{supports/disas_sm/ex2_vagues.pdf}
\end{center}
\caption{GFC paramétré par l'exécution démarrant avec \eax=-2}
\label{fig:sm_cfg_vagues}
\end{figure}


L'idée consiste donc à obtenir une exécution particulière d'un programme puis à augmenter la couverture de code à l'aide d'une analyse statique sur chaque instantané de l'exécution. Nous discuterons de la pertinence de cette approche.


\FloatBarrier
\section{Approche hybride}
% Nous avons vu comment séparer une trace d'exécution en plusieurs sous-traces définissant des vagues d'exécution.
% Chaque sous trace, au sein d'une vague, ne présente pas d'auto-modification.
% Nous décidons alors d'effectuer, pour chaque vague, un désassemblage par analyse statique en séparant le code en plusieurs \layers. Cette analyse est pertinente si les vagues ne présentent pas d'auto-modification. Nous discuterons ce point\todo{todo}.

Notre objectif est donc de construire un GFC paramétré par une exécution représentative du programme à analyser.
L'analyse dynamique du programme est faite selon l'algorithme \ref{algo:analyse_dyn_vagues} du chapitre \ref{chap:auto-modification} et fournit une trace d'exécution générale et un découpage de l'exécution en plusieurs instantanés de la mémoire.
Nous obtenons les traces et les instantanés par instrumentation avec Pin comme indiqué au chapitre précédent.
L'architecture générale du désassembleur est donnée par la figure \ref{fig:diag_codisasm}.

% \subsection{Architecture générale}
\begin{figure}[h]
\begin{center}
\scalebox{1}{
\begin{tikzpicture}[->,scale=1,>=stealth',thick]
\newcommand\espace{0.3cm}
\node[state] (BIN){Binaire};
\node[state, above right=2cm and 3.8cm of BIN] (TRACE) {Trace};
\node[state, below=1.8cm of TRACE.west, anchor=west] (I0) {Instantané 0};
\node[state, below=3.0cm of TRACE.west, anchor=west] (I1) {Instantané 1};
\node[state, below=4.2cm of TRACE.west, anchor=west] (Ip) {Instantané ...};
\node[state, below=5.4cm of TRACE.west, anchor=west] (In) {Instantané n};
% \node[state, right=1.4cm  of BIN] (ASM){ASM};
% \node[state, right=1.4cm of ASM] (IR){LI};

\node[state, right=4cm of I0] (V0) {Vague 0};
\node[state, below=1.2 of V0.west, anchor=west] (V1) {Vague 1};
\node[state, below=2.4 of V0.west, anchor=west] (Vp) {Vague ...};
\node[state, below=3.6 of V0.west, anchor=west] (Vn) {Vague n};

\coordinate [right=2cm of BIN.east] (DYN);
\coordinate [right=1.6cm of TRACE.east] (C0);
\coordinate [right=0.5cm of C0] (C1);
\coordinate [right=0.5cm of C1] (Cp);
\coordinate [right=0.5cm of Cp] (Cn);
% \coordinate [above=0.1cm of C1] (C10m);
% \coordinate [below=0.1cm of C1] (C10p);
\draw [-] (TRACE.east) -- (C0);
\draw [-] (C0) -- (C1);
\draw [-] (C1) -- (Cp);
\draw [-] (Cp) -- (Cn);
\draw (C0) -- ($(C0)+(0, -1.8cm)$);
\draw (C1) -- ($(C1)+(0, -3cm)$);
\draw (Cp) -- ($(Cp)+(0, -4.2cm)$);
\draw (Cn) -- ($(Cn)+(0, -5.4cm)$);
% \draw (C1) -- (C10m);
% \draw (C10p) -- ($(C1)+(0, -1.8cm)$);
\draw [-] (BIN.east) -- node[below left=3.0cm and -3.2cm, text width=4cm](DYNAMIC){Analyse dynamique} (DYN);
\draw (DYN) |- (TRACE.west);
\draw (DYN) |- (I0.west);
\draw (DYN) |- (I1.west);
\draw (DYN) |- (Ip.west);
\draw (DYN) |- (In.west);
\draw (I0) -- (V0);
\draw (I1) -- (V1);
\draw (Ip) -- (Vp);
\draw (In) -- node[below right=0.5cm and -1.8cm, text width=4cm](STATIC){Analyse statique} (Vn);
\node [fit={($(V0.north west) + (-0.2, 0)$) ($(V1) + (0.0, 0)$) ($(Vp) + (0.0, 0)$) ($(Vn.south east) + (0.3, 0)$)}, draw, label=GFC paramétré par la trace] {};
\end{tikzpicture}
}
\end{center}
\caption{Architecture générale du désassembleur hybride}
\label{fig:diag_codisasm}
\end{figure}

\paragraph{Pertinence de l'approche.}
L'exécution à partir de laquelle on cherche à reconstruire le GFC se doit d'être représentative d'une exécution standard du programme sur une machine cible.
Dans le cas des programmes malveillants on tente donc de se faire passer pour une machine ciblée par l'attaquant pour laisser le programme mener son attaque. 
À part les informations provenant du système d'exploitation, un programme malveillant ne prend en général pas d'entrée et ne nécessite pas d'interaction avec l'utilisateur. Une seule exécution devrait donc permettre d'analyser son comportement.
D'autre part la plupart des logiciels malveillants sont compilés sans comportement auto-modifiant et sont ensuite empaquetés. C'est le binaire empaqueté qui est obscurcis et auto-modifiant.
Dans ce cas il est fréquent \cite{Calvet2013} que la charge utile, c'est à dire le binaire d'origine, ne soit activé qu'à la dernière vague de l'exécution.
Par conséquent c'est principalement le logiciel de protection qui peut empêcher l'exécution de référence d'être représentative en détectant que le programme est instrumenté, débogué ou émulé et en détournant l'exécution dans ce cas.

Dans beaucoup de cas le programme de protection essaye de détecter qu'une analyse est en cours et oriente le programme vers un arrêt n'exécutant par la charge finale.
La difficulté est donc d'obtenir une des deux exécutions activant la charge finale présente à l'instantané $s_6$, comme illustré sur la figure \ref{fig:arbre_vagues2} reprenant l'arbre des traces possibles présenté lors de la définition du désassemblage parfait (section \ref{sec:gfc_parfait}) : les deux points de sortie présents dans l'instantané $s_4$ ne sont activés que parce que la protection a détecté que le programme était analysé et celui-ci n'a donc pas activé la charge finale.


\begin{figure}[h]
\begin{center}
\begin{tikzpicture}[->,
%   tlabel/.style={pos=0.4,right=-1pt},
%   every node/.style={color=black, circle, minimum size=10mm, draw=black, align=center},
%   edge from parent/.style={->, draw=black},
%   level 1/.style={sibling distance=30mm, level distance=15mm},
  thick
]
\node [shape=rectangle, draw] (ROOT) {$s_1$}
% \node (S11){Site 1};
child {node [shape=rectangle, draw] (S2) {$s_2$}
child{node [shape=rectangle, draw] (S3) {$s_1$}
child {node [shape=rectangle, draw] (S4) {$s_5$}
  child {node [shape=rectangle, draw] (S6) {$s_6$}}
}
}
child{node (S7) {$s_3$}
child {node (S8) {$s_4$}
}
}
child {node (S9) {$s_4$}}
};
% \draw (S4) -> (S5);
\path (ROOT) edge (S2);
\path (S2) edge (S3);
\path (S2) edge (S7);
\path (S2) edge (S9);
\path (S3) edge (S4);
\path (S4) edge (S6);
\path (S7) edge (S8);
\path (S7) edge (S4);
\node[draw=none, left=2.5cm of ROOT.west, anchor=east, text width=5cm, minimum size=5cm] (V1){Niveau d'exécution (X) 1};
\node[draw=none, below=15mm of V1.north, text width=5cm, minimum size=5cm] (V2){Niveau d'exécution (X) 2};
\node[draw=none, below=15mm of V2.north, text width=5cm, minimum size=5cm] (V3){Niveau d'exécution (X) 3};
\node[draw=none, below=15mm of V3.north, text width=5cm, minimum size=5cm] (V4){Niveau d'exécution (X) 4};
\node[draw=none, below=15mm of V4.north, text width=5cm, minimum size=5cm] (V5){Niveau d'exécution (X) 5};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
% \node[draw=none, left=4cm of ROOT.west, anchor=east, text width=1.1cm, minimum size=1.2cm] (V1){Vague 1};
\end{tikzpicture}
\end{center}
\caption{Différents instantanés des traces d'exécution et trace privilégiée}
\label{fig:arbre_vagues2}
\end{figure}


\imore{citer des cas de détection}

% \subsection{Obtention des traces et des vagues}
\FloatBarrier
\subsection{Analyse statique de chaque instantané}
Pour l'analyse statique nous disposons de la trace et des instantanés munis de leurs points d'entrée et sortie respectifs.
Nous cherchons, à partir de la trace et d'un instantané, à reconstruire la vague correspondante, c'est à dire le désassemblage parfait de l'instantané.
Nous appelons trace partielle la liste des éléments de la trace qui sont exécutés au même niveau d'exécution que l'instantané étudié.
Nous utilisons la trace partielle comme guide dans l'analyse de l'instantané. Toute instruction présente dans la trace est nécessaire du code et doit être inclue dans la vague et le GFC.

\paragraph{Reconstruction du GFC par parcours récursif.}
Nous effectuons un désassemblage par parcours récursif de l'instantané à partir de chaque instruction présente dans la trace partielle.
Dans le GFC partiel reconstitué, les instructions présentes dans la trace sont en rose, les autres en blanc. Le point d'entrée et le point de sortie sont colorés en orange et bleu clair respectivement.
Si deux instructions se suivent dans la trace alors l'arc dirigé les reliant provient de l'analyse dynamique et est plein. Si elles se suivent dans l'analyse récursive alors l'arc dirigé provient de l'analyse statique et est en pointillés. Un arc étant parcouru par l'analyse dynamique et statique est en gras. Les arcs en noir relie une instruction et l'instruction séquentielle suivante tandis que les arcs en noir représentent le saut d'un appel ou d'un saut (\call\ ou \jmp\ par exemple).

\paragraph{Point de sortie.}
La dernière instruction présente dans la trace partielle constitue le point de sortie de l'instantané.
Dans le cas où cette instruction n'est exécutées qu'une seule fois dans la trace partielle, c'est à dire que le changement de niveau d'exécution intervient dès qu'elle est exécutée la première fois, nous stoppons le parcours du programme après cette instruction en considérant que les instructions suivantes doivent être analysées dans l'instantané suivant.

\paragraph{Chemins invalides.}
Si tous les chemins d'exécution passant par une instruction $D$ aboutissent nécessairement sur une instruction provoquant une erreur, soit parce que son adresse n'est pas valide, soit parce qu'elle n'est pas une adresse \xq\ valide, alors l'instruction $D$ n'est pas valide non plus.
Nous n'incluons donc par ces instructions dans le GFC.
Une instruction dont les chemins aboutissent à un saut dont les cibles ne sont pas connues ne sont pas concernées puisqu'il est possible qu'une de ces cibles soit valide.


\paragraph{Mesure du chevauchement à l'aide des \layers.}
Nous utilisons le découpage cohérent en \layers\ adapté au parcours récursif défini à la section \ref{sec:layers_decoupage_recursif} du chapitre \ref{chap:chevauchement}.
Dans le GFC deux instructions qui se chevauchent sont liées par un arc noir non dirigé tracé en pointillés.


\paragraph{Construction des blocs de base.}
Dans les exemples de GFC déjà vus précédemment, nous avons regroupé certaines instructions dans le même bloc, dit bloc de base, lorsque le regroupement aide à la lisibilité et ne fait pas perdre d'informations. Nous regrouperons deux instructions $I_1$ et $I_2$ du GFC si et seulement si :
\begin{itemize}
 \item Elles se suivent séquentiellement : elles sont reliées par un arc dirigé de $I_1$ vers $I_2$ de couleur noire, et
 \item $I_1$ n'a pas d'autres arcs sortant que celui aboutissant sur $I_2$
 \item $I_2$ n'a pas d'autres arcs entrant que celui provenant de $I_1$
 \item $I_1$ et $I_2$ ne sont pas en chevauchement avec d'autres instructions
\end{itemize}

\section{Revue de littérature}
\subsection{Analyse dynamique}
Une application directe de l'analyse des GFC faite dans ce chapitre est la reconstitution de l'original d'un binaire empaqueté.
Renovo \cite{renovo} et PolyUnpack \cite{polyunpack} implémentent de tels systèmes d'extraction qui fonctionnent par analyse du code généré dynamiquement en utilisant des notions similaires à nos instantanés d'exécution. Ils considèrent que le binaire d'origine est celui disponible dans le dernier instantané, qui ne sera plus modifié dans la suite de l'exécution.
Leur objectif étant de reconstruire le programme d'origine, dépaqueté, ces deux approches s'arrêtent à cette étape et n'effectuent pas d'analyse supplémentaire. 

Pour l'évaluation les auteurs de PolyUnpack utilisent des programmes malveillants qu'ils analysent avec des antivirus existants (ClamAV et McAfee) et montrent que pour certains échantillons les programmes d'origine (empaquetés) ne sont pas détectés tandis que les programmes reconstruits par leur outil sont détectés.

Les auteurs de Renovo utilisent des empaqueteurs pour protéger un binaire légitime, \texttt{notepad.exe}. Ils analysent ensuite les binaires protégés et montrent qu'ils arrivent à récupérer le programme d'analyse en comparant la section \ptext\ du \texttt{notepad.exe} d'origine avec celle du programme reconstruit.


\subsection{Interprétation abstraite et analyse hybride}
Nous présentons ici des approches qui pourraient remplacer l'analyse statique simple par parcours récursif effectuée dans le cadre de ce chapitre sur les instantanés à l'aide de la trace d'exécution. Cependant elles ne sont pas aptes à remplacer l'analyse dynamique puisqu'elles sont effectuées sur des programmes non \sms.

L'analyse statique est souvent réalisée à l'aide d'une interprétation abstraite \cite{CousotC77}, méthode basée sur la définition d'une sémantique permettant d'obtenir une \sura\ des actions de chaque instructions et donc de travailler sur une \sura\ du GFC.
Kinder et Kravchenko \cite{jakstab-alternating} proposent une technique basée sur une sémantique concrète et une sémantique de \sura, alternant entre l'une et l'autre pour obtenir des résultats plus précis : il s'agit donc aussi en une sens d'une approche hybride.

Bardin, Herrmann et Védrine \cite{BHV11} proposent une méthode d'interprétation abstraite permettant de définir des niveaux de précision souhaités pour certaines variables, en particulier pour les instructions de saut dynamique. 
Une première analyse trouve des approximations grossières sur les valeurs, puis les variables dont on cherche à connaître précisément la valeur sont à nouveau analysées, jusqu'à obtenir le niveau de précision suffisant (ou échouer).
Cette approche a montré son efficacité pour déterminer les cibles de sauts dynamiques et donc pour reconstruire les GFC.


\section{Implémentation}
\paragraph{Analyse dynamique.}
Nous avons implémenté l'analyse dynamique avec l'outil d'instrumentation d'Intel, Pin, comme expliqué au chapitre \ref{chap:auto-modification} traitant de l'auto-modification.
L'implémentation permet de suivre les instructions exécutées dans la mémoire du processus instrumenté et gère les allocations dynamiques.
Chaque instantané est enregistré sous la forme d'un fichier exécutable (PE sous Windows et ELF sous Linux) dans lequel les sections ont été mises à jour et des sections supplémentaires sont ajoutées dans le cas où le programme utilise des allocations dynamiques.

\paragraph{Désassembleur.}
Le désassembleur fonctionnant par analyse statique et récursive a été codé en 3500 lignes de C++. Il utilise l'outil XED d'Intel \cite{xed} fournissant les informations sémantiques suffisantes, comme détaillé au chapitre \ref{chap:semantique}.

\section{Résultats}
Afin de valider notre approche nous avons d'abord testé notre désassembleur sur une version protégée d'un binaire existant.
Dans un second temps, afin d'obtenir des statistiques sur l'utilisation de certaines méthodes de protection, nous avons utilisé notre désassembleur pour analyser un grand nombre de programmes malveillants.

\subsection{Expérience sur \hostname\ empaqueté}
Nous avons utilisé des empaqueteurs existants pour protéger un programme standard présent sous Windows, \hostname, et avons cherché à analyser le programme protégé ainsi généré avec notre méthode hybride.
L'analyse dynamique est réussie si le programme protégé instrumenté présente la même sortie que le programme d'origine, c'est à dire s'il affiche le nom de la machine. Sur les 34 logiciels d'empaquetage que nous avons évalué, 6 produisent un binaire protégé que nous n'avons pas réussi à instrumenter jusqu'à obtenir le nom de la machine.
L'échec de l'instrumentation signifie que le logiciel de protection détecte l'utilisation d'une instrumentation et arrête prématurément l'exécution du programme.

\paragraph{Difficultés.}
Outre les quelques échantillons que nous n'avons pas réussi à instrumenter, l'empaqueteur \texttt{pespin} modifie en mémoire l'entête du fichier PE qui le représente. Ce n'était pas une possibilité que nous avions anticipé et puisqu'il ne s'agit pas d'une allocation d'une nouvelle zone mémoire nous ne sommes pas en mesure de prendre en compte cette modification dans les instantanés.
Bien qu'il s'agisse d'un problème surmontable en enregistrant à part les entêtes modifiés, nous n'avons à ce jour par implémenté cette solution et donc certaines vagues de \texttt{pespin} présentent des erreurs lors du désassemblage.

\paragraph{Métriques.}
Nous avons analyse chaque niveau d'exécution et reconstruit des graphes de flot de contrôle partiels à pour chaque vague ainsi que le graphe de flot de contrôle paramétré par l'exécution. Nous avons retenu les informations suivantes.
\begin{itemize}
 \item Le nombre d'instructions à chaque niveau d'exécution, d'une part dans la trace d'exécution, d'autre part le nombre total d'instructions récupérées par le désassemblage.
 \item Le nombre d'instructions étant en chevauchement avec une autre instruction, d'une pour les instructions de la trace, d'autre part pour toutes les instructions désassemblées.
 \item Le nombre de \layers\ de code, d'une part en ne prenant en compte que les instructions de la trace, d'autre part en prenant toutes les instructions désassemblées, selon l'algorithme \ref{algo:ajout_inst_layers} du chapitre précédent.
 \item Le nombre de sauts entre des \layers\ de code différent, d'une part en ne comptant que ceux provenant de la trace, d'autre part en comptant tous les sauts du graphe de flot de contrôle reconstruit par le désassembleur.
%  \item Le nombre d'appels (\call) non standard
 \item Le part du graphe de flot de contrôle du programme \hostname\ d'origine que l'on retrouve dans chaque vague : $100\%$ indique que l'intégralité du graphe de flot de contrôle de \hostname\ est retrouvé dans le graphe de flot de contrôle de la vague. Cette métrique sera formalisée dans la partie suivante de cette thèse.
 \item Le statut : cette colonne indique si l'instrumentation a été un échec (\checkf), si le désassemblage est un succès complet (\checkv) ou si le désassemblage a rencontré des erreurs (``partiel'').
\end{itemize}
Les données résultant de cette expérience sont données en annexe \ref{annex:packers} et un extrait donnant le résultats sur le fichier d'origine, celui protégé par tElock99 et celui protégé par \upx\ est donné en figure \ref{fig:packers_extrait}.

\begin{figure}[h]
\begin{tiny}
 \input{annexes/packers_extraits.table}
\end{tiny}
\caption{Extrait du résultat du désassemblage de \hostname\ protégé}
\label{fig:packers_extrait}
\end{figure}

% \subsubsection{Interprétations}
\paragraph{Vagues et binaire d'origine.}
Nos expériences confirment un fait étudié précédemment \cite{Calvet2013,renovo,polyunpack} indiquant que la charge utile, cachée par l'empaqueteur, se trouve dans la dernière vague.
Nous montrons que tous les cas de détection massive de \hostname\ au sein d'un binaire protégé se font dans la dernière vague.
De plus nous validons également l'utilisation systématique de l'auto-modification comme technique de protection : le seul empaqueteur ne présentant pas d'auto-modification est vmprotect qui utilise une technnique d'émulation de code et n'exécute pas directement le code d'origine sur la machine.

On peut distinguer deux cas différents de protection. UPX, comme d'autres empaqueteurs simples, présente le programme d'origine dans son intégralité et non modifié en dernière vague : les caractéristiques de la dernière vague d'UPX sont exactement les mêmes que celle de l'unique vague de \hostname. L'empaqueteur tElock99 présente le code de \hostname\ également en dernière vague mais il est mêlé à d'autre code : la dernière vague est également obscurcie.

\paragraph{Utilisation du chevauchement de code et \layers.}
De nombreux binaires protégés (22 sur 28) présentent, dans le graphe que nous reconstruisons, des chevauchements de code et donc plus d'une couche de code. Pourtant seuls 9 de ces binaires ont utilisé des instructions en chevauchement lors de leur exécution : les autres binaires utilisent en fait des techniques d'obscurcissement qui conduisent notre désassembleur à considérer des instructions se chevauchant sans en faire un usage actif. 

Ainsi seules les variantes de tElock, UPX et pespin utilisent réellement le chevauchement de code et ils l'utilisent avec parcimonie : au plus une douzaine d'instructions sont en chevauchement dans la trace (sur plusieurs centaines) et il n'y a au plus que deux couches de code dans la trace.

Nous concluons que peu d'empaqueteurs utilisent le chevauchement de code lors de leur exécution mais la plupart obscurcissent le code de manière à amener le désassembleur à considérer des instructions en chevauchement.

\subsection{Expérience sur des logiciels malveillants}
\begin{rem}
 Les résultats présentés dans cette sous-section sur un grand nombre de programmes malveillants sont des résultats obtenus à l'aide d'une version préliminaire du désassembleur. Nous les mettrons à jour avant la soutenance.
\end{rem}


\section{Conclusion}
Nous avons combiné les notions d'analyse statique et d'analyse dynamique vues aux chapitres précédents pour réaliser et implémenter un désassembleur capable de construire un graphe de flot de contrôle approchant le graphe de flot parfait d'un programme \sm, notion que nous avons définie.