\itodo{désassemblage parfait dans le cas sm}

Nous avons jusqu'à présent fait l'hypothèse \todo{todo} que les programmes analysés ne sont pas auto-modifiants.
Dans ce chapitre nous détaillons une approche d'analyse dynamique adaptée aux programmes auto-modifiants et ayant pour but de réduire l'analyse d'un programme auto-modifiant en l'analyse de plusieurs sous-ensembles non auto-modifiants du programme.
Cette approche est donnée par la littérature existante, en particulier par les travaux de thèse de Reynaud \cite{Reynaud2010} et Calvet \cite{Calvet2013}.

\section{Auto-modification et vagues}
Si on reprend l'exemple de code auto-modifiant du chapitre précédent (figure \ref{fig:unevague_v0}), on peut construire trois représentations en mémoire des parties exécutables du programme.
La première correspond à la vision du programme lors de son chargement : la section .text est dans son état initial.
La seconde est celle après que la première modification du programme faite à l'adresse \adr{8048086} et la troisième après la seconde modification faite à l'adresse \adr{804808b}.
En fait vu qu'aucune des adresses modifiées par la première instruction auto-modifiante n'est exécutées avant que la seconde modification ne soit faite, on peut regrouper les deux instructions auto-modifiantes et considérer que le programme n'a que deux représentations en mémoire : la représentation initiale et la représentation au moment où l'instruction modifiée à l'adresse \adr{8048091} est exécutée.

Dans ce découpage informel on appelle vague une représentation mémoire à un instant donné. 
L'exécution d'un programme est alors caractérisée par une suite d'exécutions sur des vagues successives comme représenté en figure \ref{fig:vagues_visuel}. Les instructions qui sont présentes dans la trace sont colorées en rose tandis que le point d'entrée et la dernière instruction sont en orange et bleu clair, respectivement.
On passe d'une vague $k$ à la vague suivante $k+1$ lorsqu'une adresse mémoire écrite dans la vague $k$ est exécutée.
Ainsi dans une vague $k$, toutes les instructions exécutées ont été écrites au moins à la vague $k-1$. 
En ce sens chacune des vagues, prise indépendamment des autres, ne présente pas d'auto-modification.

Nous détaillerons par la suite ce qu'est une trace d'exécution pour l'analyse dynamique ainsi que la sémantique d'enchaînement des vagues.

\begin{figure}
 \includegraphics[width=1.0\textwidth]{supports/automodification/phases2_final.pdf}
 \caption{Vision informelle des vagues}
 \label{fig:vagues_visuel}
\end{figure}


\section{Revue de littérature}
La notion de vague présentée dans ce chapitre a été développée dans les thèse de Reynaud \cite{Reynaud2010} et Calvet \cite{Calvet2013}.
Elle est similaire à la notion de \emph{phase} présentée par Debray et Patel \cite{DP10} et utilisée pour automatiser la suppression de la protection d'un binaire. Le découpage d'une trace en phases est, chez eux, identique au découpage en vagues que l'on présent dans ce chapitre.
En général la suppression des protections se fait à l'aide d'une analyse dynamique et d'une image de la mémoire à un instant donné au cours de l'exécution. C'est cette image mémoire qui sera considérée comme étant le programme d'origine. La difficulté réside alors dans le choix de l'instant où prendre l'image mémoire.

Preda, Giacobazzi, Debray, Coogan et Townsend \cite{PGDCT10} utilisent la même notion de phases mais chaque lecture d'une instruction écrite lors d'une vague précédente (pas uniquement lors de la phase en cours) provoque la création d'une nouvelle phase.

\itodo{donner un exemple avec les différentes interprêtations}

\section{Trace, niveaux d'exécution et vagues}
Le programme exécuté a pour sources principales de données les registres et la mémoire constituée de la pile et du tas qui sont tous les deux adressables par des entiers. Une variable d'un programme est donc soit un registre du processeur soit une adresse mémoire, de même que défini dans la sémantique du langage intermédiaire défini au chapitre précédent (définition \ref{def:sem_conc_var}).

En utilisant la sémantique concrète précédemment définie on est capable, à partir d'un ensemble de valeurs initiales pour les registres et la mémoire, d'exécuter un programme sur cette entrée.
L'exécution d'un programme consiste en la définition d'un contexte d'exécution initial, l'évaluation sémantique de la première instruction dans ce contexte, puis l'évaluation de l'instruction suivante dans le contexte mis à jour, etc.

Nous définissons une instruction dynamique (définition \ref{def:ensembles_inst_dyn}) par son adresse, les adresses mémoires sur lesquelles elle est codée et l'instruction machine correspondant. Ces informations sont données par le décodage d'une instruction à l'adresse mémoire spécifiée dans un contexte donné (définition \ref{def:decode}). 
En pratique l'opération de désassemblage atomique définie au chapitre précédent nous donne ces informations. Pour l'assembleur \xq, une instruction est codée au maximum sur 15 octets. Si on cherche à désassembler \telock\ à l'adresse \adr{0x01006e7a}, et qu'à l'adresse \adr{0x01006e7d} sont présents les octets suivant : $\Theta[0x01006e7d..0x01006e8b]=$ \texttt{eb ff c9 7f e6 8b c1 29 00 00 00 f3 aa 66 ab}, l'opérateur \texttt{decode} renvoie la première instruction dynamique à cette adresse : il s'agit de l'instruction assembleur \texttt{jmp +1} (d'une taille de deux octets : \texttt{eb ff}) à l'adresse \adr{0x01006e7d}, codée sur le segment d'adresses [\adr{0x01006e7d}, \adr{0x01006e7e}].

Afin de pouvoir séparer la trace d'exécution selon le moment où chaque instruction a été écrite, nous définissons aussi, pour une instruction dynamique et un contexte d'exécution, l'ensemble des adresses mémoire sur lesquelles elle provoque une écriture (définition \ref{def:ensembles_inst_dyn_write}). Cette information est donnée par la sémantique concrète choisie. Avec la sémantique définie au chapitre précédent les seules instructions qui provoquent des écritures sont celles dont la liste d'instructions atomiques donnée par le désassemblage contiennent des assignations de la forme $x\leftarrow g(x_1, ..., x_m)$ : Si D est une instruction dynamique sémantiquement équivalente, dans le contexte $\Theta$, à l'enchaînement des instructions atomiques $d_1, ..., d_n$ alors \dww{\Theta}{D}=\dww{\Theta}{d_1..d_n}=\dww{\Theta}{d_1}$\ \cup\ ...\ \cup\ $\dww{\Theta}{d_n} avec
\\
\dww{\Theta}{d_i}$=
\left\{
  \begin{array}{ll}
	  x &$ si $d_i=m\leftarrow g(x_1, ..., x_k)\ et\ m\in\BT
	\\\Theta(v) &$ si $d_i=[v]\leftarrow g(x_1, ..., x_k)\ et\ \Theta(v)\in\BT
	\\ \emptyset &$ sinon.$
  \end{array}
\right.
$

\begin{defi}
On note $D$ une instruction dynamique constituée des éléments suivants.
\begin{itemize}
 \item \da{D} l'adresse mémoire de l'instruction dynamique
 \item \dc{D} le segment des adresses mémoire sur lequel \di{D} est codée
 \item \di{D} l'instruction machine à l'adresse \da{D}
%  \item \dr{D_i} l'ensemble des variables sur lesquelles l'exécution de \di{D_i} provoque une lecture
%  \item \dw{D} l'ensemble des variables sur lesquelles l'exécution de \di{D} provoque une écriture
\end{itemize}
\label{def:ensembles_inst_dyn}
\end{defi}

\begin{defi}
On définit l'opérateur \texttt{decode} qui associe à une adresse mémoire $a$ et un store $\Theta$ l'instruction dynamique $D=$\texttt{decode}$(a, \Theta)$ présente à l'adresse $a$ :
\begin{itemize}
 \item \da{D}$=a$
 \item \di{D} est l'instruction assembleur présente à l'adresse $a$ dans $\Theta$
 \item \dc{D} est le segment des adresses sur lequelles l'instruction assembleur est codée.
\end{itemize}
\label{def:decode}
\end{defi}

\begin{defi}
Soit $D$ une instruction dynamique et $\Theta$ un store représentant l'état des variables (mémoire et registres). On note \dww{\Theta}{D} l'ensemble des adresses mémoire sur lesquelles l'exécution de $D$ provoque une écriture.
\label{def:ensembles_inst_dyn_write}
\end{defi}

% \begin{defi}
% Nous définissons le niveau d'écriture d'une adresse mémoire comme un entier naturel et le store $W^M: \BT\rightarrow\BN$ associant à une adresse mémoire son niveau d'écriture.
% \label{def:store_mem}
% \end{defi}

\begin{defi}
Un contexte d'exécution est la donnée d'un triplet $E=(X, \Theta, W^M)$ où
\begin{itemize}
 \item $X\in\BN$ est le niveau d'exécution du contexte
 \item $\Theta$ est le store des valeurs du contexte, associant une valeur à chaque registre et chaque adresse mémoire
 \item $W^M$ est le store des niveaux d'écriture du contexte, associant à chaque adresse mémoire un niveau d'écriture dans $\BN$
\end{itemize}
Une exécution d'un programme dont le point d'entrée est $ep$ est la donnée d'une suite finie de contextes d'exécution $E_0, E_1, ..., E_n$ tel que :
\begin{itemize}
 \item $X_0=1$, $\Theta_0[eip]=ep$ et $\forall m\in \BT, W_0^M[m\leftarrow 0]$
 \item En notant $D=$\texttt{decode}$(\Theta_i[eip], \Theta_i)$ l'instruction dynamique exécutée lors de la transition entre le contexte $E_i$ et $E_{i+1}$, on a :
    \begin{itemize}
     \item Le niveau d'écriture de $D$ est le niveau d'écriture maximum des octets qui la composent : $W_D=max(\{W^M[m],\ m\in\ $\dc{D_i}$\})$
     \item $X_{i+1}=max(X_i, W_D+1)$
     \item $\Theta_{i+1}$ est $\Theta_i$ mis à jour par l'évaluation sémantique de \di{D}
     \item $W_{i+1}^M=W_{i}^M$ sauf pour les adresses mémoire écrites par $D$: $\forall m\in\ $\dw{D}$,\ W_{i+1}^M[m\leftarrow X_i]$
    \end{itemize}
\end{itemize}
\label{def:contexte_exec}
\end{defi}

Nous définissons plus formellement la notion de contexte d'exécution (définition \ref{def:contexte_exec}) comme la donnée d'un niveau d'exécution, d'un store contenant les valeurs de la mémoire et des registres et d'un store contenant les niveaux d'écriture courants de chaque adresse mémoire. 
Une exécution consiste en une série de contextes d'exécution liés dont la transition est provoquée par l'évaluation sémantique de l'instruction pointée par le registre de compteur ordinal (noté en général \pc\ ou \eax\ en assembleur \xq), comme illustré par la figure suivante.

% \begin{figure}
\begin{center}
\scalebox{1}{
\begin{tikzpicture}[->,scale=1,>=stealth',thick]
\node[state, draw=none] (E0){$E_0$};
\node[state, draw=none, right=2cm of E0] (E1){$E_1$};
\node[state, draw=none, right=2cm of E1] (E2){$E_2$};
\node[state, draw=none, right=2cm of E2] (EP){$...$};
\node[state, draw=none, right=2cm of EP] (EN){$E_n$};
\draw (E0.east) -> node[above]{$I_1$} (E1.west);
\draw (E1.east) -> node[above]{$I_2$} (E2.west);
\draw (E2.east) -> node[above]{...} (EP.west);
\draw (EP.east) -> node[above]{$I_n$} (EN.west);
\end{tikzpicture}
}
\end{center}
% \caption{Enchaînement des contextes d'exécution et des instructions dynamiques}
% \label{fig:mem_process}
% \end{figure}


Nous avons donc, pour une exécution donnée, des niveaux d'exécution successifs $1, 2, ..., n$.
À chaque contexte d'exécution, toute adresse en mémoire $m$ a un niveau d'écriture $W^M[m]$ correspondant au dernier niveau d'exécution durant lequel une instruction a modifié la valeur à l'adresse $m$.
Une instruction $D$ a un niveau d'écriture $W_D$ qui est le niveau d'écriture le plus élevé parmi les adresses sur lesquelles elle est codée.
Lors d'une exécution le niveau d'exécution ainsi que le niveau d'écriture de chaque adresse mémoire sont croissants.



% \begin{defi}
% Nous définissons une trace d'exécution comme la donnée d'une suite $T=t_1, t_2, ..., t_n$ composée de triplets de la forme $t_i=(i, D_i, X_i)$ tels que
% \begin{itemize}
%  \item $D_i$ est la $i^{eme}$ instruction dynamique exécutée.
%  \item Avant l'exécution de l'instruction $D_i$, le niveau d'exécution est \texttt{$X_{i-1}$}.
%  \item Après l'exécution de l'instruction $D_i$, le niveau d'exécution est \texttt{$X_i$}.
% \end{itemize}
% \label{def:write_exec_levels}
% \end{defi}

\begin{defi}
Étant donnée une exécution d'un programme composée des contextes d'exécution $E_0, E_1, ..., E_n$ avec $E_i=(X_i, \Theta_i, W_i^M)$, on appelle trace d'exécution la suite $T=(t_1, t_2, ..., t_n)$ où $t_i=(i, X_{i-1}, D_{i-1})$ avec $D_{i-1}=$\texttt{decode}$(\Theta_{i-1}[eip], \Theta_{i-1})$
\label{def:trace}
\end{defi}

% \begin{propri}
%  Si le niveau d'exécution courant est $X$, le niveau d'exécution de l'instruction à exécuter $D_i$ est :\\
%  $X=max(X, W_D+1)$ avec $W_D=max(W^M[a],\ a\in\ $\dc{D_i}$)$.\\
%  Après l'exécution de $D_i$, les niveaux d'écriture dans la mémoire sont mis à jour de la manière suivante :\\
%  $\forall a\in$ \dw{D_i}, $W^M[a]=X$.
% \label{propri:niveau_exec}
% \end{propri}

En pratique une instruction $D$ écrite par une instruction ayant pour niveau d'exécution $k$ puis directement exécutée aura pour niveau d'écriture $W_D=k$ et pour niveau d'exécution $X=k+1$. On définit alors formellement instantané du niveau d'exécution $k$ selon la définition \ref{def:instantane} et une vague comme étant le désassemblage parfait de cet instantané (définition \ref{def:vagues}).
Une première vague est définie dès l'exécution de la première instruction du programme puis à chaque changement de niveau d'exécution une nouvelle vague est construite.
L'algorithme \ref{algo:analyse_dyn_vagues} permet d'exécuter un programme dynamiquement avec la sémantique concrète choisie tout en déterminant les niveaux d'exécution de d'écriture au fur et à mesure de l'exécution. La sortie de l'algorithme \ref{algo:analyse_dyn_vagues} est la trace d'exécution et la liste des vagues reconstruites.
\\

\begin{defi}
 Étant donnée une exécution d'un programme composée des contextes d'exécution $E_0, E_1, ..., E_n$ avec $E_i=(X_i, \Theta_i, W_i^M)$, on appelle instantané du niveau d'exécution $k$ l'état de la mémoire contenu dans $\Theta_j$ où $E_j$ est le premier contexte d'exécution dont le niveau d'exécution est $X_j=k$.
 \label{def:instantane}
\end{defi}

\begin{defi}
 Étant donnée une exécution d'un programme, on appelle vague $k$ le désassemblage parfait de l'instantané du niveau d'exécution $k$.
 \label{def:vagues}
\end{defi}

Reprenons l'exemple précédent d'un programme auto-modifiant (figure \ref{fig:unevague_v0} du chapitre \ref{chap:obscurcissement}).
La figure \ref{fig:unevague_trace} donne une trace d'exécution de ce programme en détaillant les informations sur chaque instruction dynamique ainsi que les niveaux d'écriture et d'exécution de chaque instruction.
Au départ toute la mémoire est dans son état d'origine et a pour niveau d'exécution 0. Lorsque l'instruction $D_1$ est exécutée, il n'y a pas eu d'auto-modification donc le niveau d'écriture est 0 et le niveau d'exécution est 1.
Les instructions $D_3$ et $D_4$ provoquent une auto-modification : les octets aux adresses \adr{0x8048091} et \adr{0x8048092} sont modifiés et leurs niveaux d'écriture deviennent donc le niveau d'exécution courant, soit 1.
Lorsque l'exécution atteint $D_5$, qui a été modifié, le niveau d'écriture est 1 donc le niveau d'exécution devient 2.
L'instruction suivante $D_6$ fixe la valeur de \edi\ à 2 puis les instructions suivantes provoquent l'affichage de \edi.

Cette exécution est donc séparée en deux vagues : la vague initiale, $v_0$ dont l'instantané est l'état de la mémoire avant l'exécution de la première instruction et la vague $v_1$ contenant l'état de la mémoire juste après l'exécution de $D_4$ et avant l'exécution de la première instruction modifiée $D_5$.


\begin{figure}
\begin{center}
\begin{tabular}[b]{|l|l|l|l|l|l|l|}
\hline
i & \da{D_i} & \dc{D_i} & \di{D_i} & \dw{D_i} & $W_i$ & $X_i$ \\
\hline
& 8048060  &  (...)         	        & Pile -> RWX &  & 0 & 1 \\ 
1 & 804807c  &  [804807c, 8048080]         &  mov    edi, 0x0 & edi & 0 & 1 \\
2 & 8048081  &  [8048081, 8048086]         &  mov    eax, 0x8048091 & eax & 0 & 1 \\
3 & 8048086  &  [8048086, 804808a]         &  mov    [eax], 0xeb & 0x8048091 & 0 & 1 \\
4 & 804808b  &  [804808b, 8048090]         &  mov    [eax+1], 0x7 & 0x8048092 & 0 & 1 \\
5 & 8048091  &  [8048091, 8048092]         &  jmp    80480a1 <edi3> &  & 1 & 2  \\
6 & 804809a  &  [804809a, 804809d]         &  mov    edi,0x2 & edi & 0 & 2\\
7 & 804809f  &  [804809f, 80480a0]         &  jmp    80480a8 <fin> &  & 0 & 2\\
 & 80480a8  &  (...)		        &  Affiche edi &  & 0 & 2\\
 & 80480c3  &  (...)		        &  Quitte &  & 0 & 2\\
\hline
\end{tabular}
\end{center}
\caption{Trace d'exécution du programme auto-modifiant de la figure \ref{fig:unevague_v0}}
\label{fig:unevague_trace}
\end{figure}

\begin{algorithm}[h] %or another one check
\caption{Mise à jour du niveau d'exécution d'une instruction}
\SetAlgoLined
\KwIn{La mémoire, l'opérateur de niveau d'écriture, une instruction dynamique et le niveau d'exécution courant}
\KwResult{Le niveau d'exécution courant mis à jour}
\SetKwProg{Fn}{}{}{}
\SetKwFunction{FRecurs}{MAJExecution}
\Fn(
){\FRecurs{M, $W^M$, D, X}}{
$W_D \leftarrow\ max(W^M[a],\ a\in\ $\dc{D}$)$\\
$X \leftarrow\ max(X,\ W_D+1)$ \\
\Return X
}
\label{algo:update_exec_level}
\end{algorithm}

\begin{algorithm}[h] %or another one check
\caption{Mise à jour des niveaux d'écriture lors de l'exécution d'une instruction}
\SetAlgoLined
\KwIn{La mémoire, l'opérateur de niveau d'écriture, une instruction dynamique et le niveau d'exécution courant}
\KwResult{L'opérateur de niveau d'écriture mis à jour}
\SetKwProg{Fn}{}{}{}
\SetKwFunction{FRecurs}{MAJEcriture}
\Fn(
){\FRecurs{M, $W^M$, D, X}}{
\For {$m\in\ $\dw{D}}{
  $W^M[m]\leftarrow\ X$
}
\Return $W^M$
}
\label{algo:update_write_level}
\end{algorithm}

\begin{algorithm}[H] %or another one check
\caption{Analyse dynamique avec calcul des vagues}
\SetAlgoLined
\KwIn{Les registres R et une mémoire M dans laquelle un programme a été chargé à son point d'entrée \texttt{ep}}
\KwResult{La trace des instructions dynamiques chacune associée à leur niveau d'exécution et les différentes vagues de la trace}
\SetKwProg{Fn}{}{}{}
\SetKwFunction{FRecurs}{analyseDynamique}
\Fn(
% \tcc*[h]{C : matrice des associations possibles, i : numéro du prochain sommet de P à associer, F : liste des couples d'associations déjà faites}
){\FRecurs{R, M, ep}}{
\For{$m\in M$}{
  $W^M[m]\leftarrow 0$\\
}
$(X, X_{-1}, i, T, instantanes, eip)\leftarrow (1, 0, 1, \emptyset, \emptyset, ep)$\\
% $X\leftarrow 1$\\
% $X_{-1}\leftarrow 0$\\
% $i\leftarrow 0$\\
% $T\leftarrow \emptyset$\\
% $vagues\leftarrow \emptyset$\\
% $eip\leftarrow ep$\\
\While {la fin du programme n'est pas atteinte}{
\tcc{Le programme est exécuté en prenant l'instruction suivante à l'adresse eip}
$D\leftarrow decode(eip, M)$\\
$X\leftarrow MAJExecution(M, W^M, D, X)$\\
\If {$X \ne X_{-1}$}{
  \tcc{Quand le niveau d'exécution change, on prend un instantané de la mémoire}
  $instantanes\leftarrow instantanes\cup \{(X_{-1}, M)\}$
}
$X_{-1} \leftarrow X$\\
~\\
\tcc{On met à jour le contexte à partir de l'instruction courante en l'évaluant sémantiquement}
$(eip, R, M)\leftarrow sem\_eval(eip, R, M)$\\
$W^M\leftarrow MAJEcriture(M, W^M, D, X)$\\
$T\leftarrow T\cup\{(i, X, D_i)\}$\\
$i\leftarrow i+1$\\
}
\Return T, instantanes
}
\label{algo:analyse_dyn_vagues}
\end{algorithm}

\begin{rem}
 Étant donné la définition croissante des vagues, une instruction dynamique peut-être exécutée non seulement plusieurs fois dans la même vague mais également être présente à des vagues différentes.
\end{rem}

\section{Implémentations}
\todo[inline]{émulation VS instrumentation VS débogage}
\todo[inline]{BAP: \\
Jakstab: \\
TraceSurfer: (outil de daniel)\\
Renovo : \\
LLVM : (pk ne pas l'utiliser??) \\
Implem en C: \\
Xed : \\
}

Plusieurs choix s'offrent à qui cherche à implémenter un système d'analyse dynamique de binaire tels l'émulation, l'instrumentation et le débogage

L'émulation consiste à lancer l'exécution dans un environnement d'exécution simulé, qui peut être un système d'exploitation complet comme c'est le cas avec TEMU, le module d'analyse dynamique du projet BitBlaze BAP \cite{bitblaze08}, basé sur l'émulateur QEMU \cite{QEMU05}.

On instrumente un binaire exécuté en y insérant, généralement au cours de son exécution, du code assembleur servant à son analyse. Intel développe PinTools \cite{pintools} pour l'analyse de programmes tournant sur leurs processeurs.

Enfin le débogage suit pas à pas l'exécution d'un programme en utilisant le drapeau de trappe (\emph{Trap Flag}), permettant de reprendre la main après chaque instruction du programme débogué afin d'examiner son environnement d'exécution.
\\

Le débogage comme l'instrumentation n'utilisent pas de langage intermédiaire tandis qu'un émulateur tel que BAP transcrit d'abord les instructions dans son langage intermédiaire pour les exécuter avec la sémantique concrète du langage intermédiaire.
L'émulation est donc intéressante parce qu'à aucun moment le programme analysé n'a un accès libre au système sur lequel il s'exécute.
La limitation est donc que les interactions du programme émulé avec le système d'exploitation visé sont restreintes.
En particulier les appels systèmes, qui ne sont pas transcrits par BAP, ne peuvent pas être émulés directement, rendant l'analyse très partielle.
Les approches nécessitant une exécution non restreinte sur le système sont alors réalisées au sein d'une machine virtuelle.

Une caractéristique cruciale d'un analyseur dynamique est qu'il doit être transparent : le programme analysé ne doit pas être capable de différencier son exécution dans l'analyseur de son exécution sur un système réel.
Cette transparence est en général partielle, que ce soit avec un émulateur, un débogueur ou une technique d'instrumentation.

L'instrumentation, par rapport au débogage, offre des performances temporelles d'exécution bien supérieures.
Pour ces raisons, nous nous sommes intéressés à l'émulation comme à l'instrumentation.
\\

L'émulation permet une analyse plus abstraite et nous avons développé un analyseur partiel de programmes auto-modifiants basé sur BAP.
L'instrumentation permet d'exécuter plus fidèlement le programme à analyser, nous avons donc principalement favorisé cette approche pour l'analyse de programmes malveillants. Nous avons choisi Pin qui, sans fournir de sémantique concrète pour l'assembleur, permet d'obtenir d'une instruction dynamique l'ensemble des adresses sur lesquelles elle écrit, comme souhaité à la définition \ref{def:ensembles_inst_dyn}.



\section{Émulation avec BAP}


\section{Instrumentation avec Pin}


